

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Camera Calibration &mdash; OpenCV Documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="_static/target-highlight.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-sphinx_rtd_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Depth Map from Stereo Images" href="page_tutorial_py_depthmap.html" />
    <link rel="prev" title="Camera Calibration and 3D Reconstruction" href="page_tutorial_py_table_of_contents_calib3d.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> OpenCV Documentation
          

          
          </a>

          
            
            
              <div class="version">
                3.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="group_features2d.html">2D Features Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_viz.html">3D Visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_calib3d.html">Camera Calibration and 3D Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_flann.html">Clustering and Search in Multi-Dimensional Spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_photo.html">Computational Photography</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_core.html">Core functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_highgui.html">High-level GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgcodecs.html">Image file reading and writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgproc.html">Image processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_stitching.html">Images stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_objdetect.html">Object Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_shape.html">Shape Distance and Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_superres.html">Super Resolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_video.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videoio.html">Video I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videostab.html">Video Stabilization</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="page_citelist.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_cuda_intro.html">CUDA Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_imgproc_color_conversions.html">Color conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_deprecated.html">Deprecated List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_ml_intro.html">Machine Learning Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_tutorial_root.html">OpenCV Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_index.html">OpenCV modules</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="page_tutorial_py_table_of_contents_calib3d.html">Camera Calibration and 3D Reconstruction</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Camera Calibration</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_depthmap.html">Depth Map from Stereo Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_epipolar_geometry.html">Epipolar Geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_pose.html">Pose Estimation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_photo.html">Computational Photography</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_core.html">Core Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_gui.html">Gui Features in OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_imgproc.html">Image Processing in OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_setup.html">Introduction to OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_objdetect.html">Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_bindings.html">OpenCV-Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_video.html">Video Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="page_todo.html">Todo List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_videoio_overview.html">Video I/O with OpenCV Overview</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example_contours2.cpp.html">contours2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_convexhull.cpp.html">convexhull.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_cout_mat.cpp.html">cout_mat.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_demhist.cpp.html">demhist.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_distrans.cpp.html">distrans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_edge.cpp.html">edge.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_ffilldemo.cpp.html">ffilldemo.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_filestorage.cpp.html">filestorage.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_fitellipse.cpp.html">fitellipse.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_grabcut.cpp.html">grabcut.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghcircles.cpp.html">houghcircles.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghlines.cpp.html">houghlines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_kmeans.cpp.html">kmeans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_laplace.cpp.html">laplace.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_lsd_lines.cpp.html">lsd_lines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_minarea.cpp.html">minarea.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_morphology2.cpp.html">morphology2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_pca.cpp.html">pca.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_polar_transforms.cpp.html">polar_transforms.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_segment_objects.cpp.html">segment_objects.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_watershed.cpp.html">watershed.cpp</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="global.html">Global Namespace</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenCV Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_table_of_contents_calib3d.html">Camera Calibration and 3D Reconstruction</a> &raquo;</li>
        
      <li>Camera Calibration</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="camera-calibration">
<span id="doxid-dc-dbb-tutorial-py-calibration"></span><span id="index-0"></span><h1>Camera Calibration</h1>
<p class="rubric">Goal</p>
<p>In this section,</p>
<ul class="simple">
<li>We will learn about distortions in camera, intrinsic and extrinsic parameters of camera etc.</li>
<li>We will learn to find these parameters, undistort images etc.</li>
</ul>
<p class="rubric">Basics</p>
<p>Today’s cheap pinhole cameras introduces a lot of distortion to images. Two major distortions are radial distortion and tangential distortion.</p>
<p>Due to radial distortion, straight lines will appear curved. Its effect is more as we move away from the center of image. For example, one image is shown below, where two edges of a chess board are marked with red lines. But you can see that border is not a straight line and doesn’t match with the red line. All the expected straight lines are bulged out. Visit <a class="reference external" href="http://en.wikipedia.org/wiki/Distortion_%28optics%29">Distortion (optics)</a> for more details.</p>
<img alt="image" src="_images/calib_radial.jpg" />
<p>This distortion is represented as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x_{distorted} = x( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \\ y_{distorted} = y( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6)\end{split}\]</div>
<p>Similarly, another distortion is the tangential distortion which occurs because image taking lense is not aligned perfectly parallel to the imaging plane. So some areas in image may look nearer than expected. It is represented as below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x_{distorted} = x + [ 2p_1xy + p_2(r^2+2x^2)] \\ y_{distorted} = y + [ p_1(r^2+ 2y^2)+ 2p_2xy]\end{split}\]</div>
<p>In short, we need to find five parameters, known as distortion coefficients given by:</p>
<div class="math notranslate nohighlight">
\[Distortion \; coefficients=(k_1 \hspace{10pt} k_2 \hspace{10pt} p_1 \hspace{10pt} p_2 \hspace{10pt} k_3)\]</div>
<p>In addition to this, we need to find a few more information, like intrinsic and extrinsic parameters of a camera. Intrinsic parameters are specific to a camera. It includes information like focal length (<span class="math notranslate nohighlight">\(f_x,f_y\)</span>), optical centers (<span class="math notranslate nohighlight">\(c_x, c_y\)</span>) etc. It is also called camera matrix. It depends on the camera only, so once calculated, it can be stored for future purposes. It is expressed as a 3x3 matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}camera \; matrix = \left [ \begin{matrix} f_x &amp; 0 &amp; c_x \\ 0 &amp; f_y &amp; c_y \\ 0 &amp; 0 &amp; 1 \end{matrix} \right ]\end{split}\]</div>
<p>Extrinsic parameters corresponds to rotation and translation vectors which translates a coordinates of a 3D point to a coordinate system.</p>
<p>For stereo applications, these distortions need to be corrected first. To find all these parameters, what we have to do is to provide some sample images of a well defined pattern (eg, chess board). We find some specific points in it ( square corners in chess board). We know its coordinates in real world space and we know its coordinates in image. With these data, some mathematical problem is solved in background to get the distortion coefficients. That is the summary of the whole story. For better results, we need atleast 10 test patterns.</p>
<p class="rubric">Code</p>
<p>As mentioned above, we need atleast 10 test patterns for camera calibration. OpenCV comes with some images of chess board (see samples/cpp/left01.jpg left14.jpg), so we will utilize it. For sake of understanding, consider just one image of a chess board. Important input datas needed for camera calibration is a set of 3D real world points and its corresponding 2D image points. 2D image points are OK which we can easily find from the image. (These image points are locations where two black squares touch each other in chess boards)</p>
<p>What about the 3D points from real world space? Those images are taken from a static camera and chess boards are placed at different locations and orientations. So we need to know <span class="math notranslate nohighlight">\((X,Y,Z)\)</span> values. But for simplicity, we can say chess board was kept stationary at XY plane, (so Z=0 always) and camera was moved accordingly. This consideration helps us to find only X,Y values. Now for X,Y values, we can simply pass the points as (0,0), (1,0), (2,0), … which denotes the location of points. In this case, the results we get will be in the scale of size of chess board square. But if we know the square size, (say 30 mm), and we can pass the values as (0,0),(30,0),(60,0),…, we get the results in mm. (In this case, we don’t know square size since we didn’t take those images, so we pass in terms of square size).</p>
<p>3D points are called <strong>object points</strong> and 2D image points are called <strong>image points.</strong></p>
<p class="rubric">Setup</p>
<p>So to find pattern in chess board, we use the function, <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1ga93efa9b0aa890de240ca32b11253dd4a"><span class="std std-ref">cv2.findChessboardCorners()</span></a>. We also need to pass what kind of pattern we are looking, like 8x8 grid, 5x5 grid etc. In this example, we use 7x6 grid. (Normally a chess board has 8x8 squares and 7x7 internal corners). It returns the corner points and retval which will be True if pattern is obtained. These corners will be placed in an order (from left-to-right, top-to-bottom)</p>
<p>Once we find the corners, we can increase their accuracy using <a class="reference internal" href="group_imgproc_feature.html#doxid-dd-d1a-group-imgproc-feature-1ga354e0d7c86d0d9da75de9b9701a9a87e"><span class="std std-ref">cv2.cornerSubPix()</span></a>. We can also draw the pattern using <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1ga6a10b0bb120c4907e5eabbcd22319022"><span class="std std-ref">cv2.drawChessboardCorners()</span></a>. All these steps are included in below code:</p>
<pre class="highlight literal-block">
<span></span><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">cv2</span>
<span class="n">import</span> <span class="n">glob</span>

<span class="cp"># termination criteria</span>
<span class="n">criteria</span> <span class="o">=</span> <span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">TERM_CRITERIA_EPS</span> <span class="o">+</span> <span class="n">cv2</span><span class="p">.</span><span class="n">TERM_CRITERIA_MAX_ITER</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>

<span class="cp"># prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)</span>
<span class="n">objp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">6</span><span class="o">*</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">objp</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mgrid</span><span class="p">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">7</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">6</span><span class="p">].</span><span class="n">T</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="cp"># Arrays to store object points and image points from all the images.</span>
<span class="n">objpoints</span> <span class="o">=</span> <span class="p">[]</span> <span class="err">#</span> <span class="mi">3</span><span class="n">d</span> <span class="n">point</span> <span class="n">in</span> <span class="n">real</span> <span class="n">world</span> <span class="n">space</span>
<span class="n">imgpoints</span> <span class="o">=</span> <span class="p">[]</span> <span class="err">#</span> <span class="mi">2</span><span class="n">d</span> <span class="n">points</span> <span class="n">in</span> <span class="n">image</span> <span class="n">plane</span><span class="p">.</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="sc">&#39;*.jpg&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">fname</span> <span class="n">in</span> <span class="nl">images</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

    <span class="cp"># Find the chess board corners</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">corners</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">findChessboardCorners</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">None</span><span class="p">)</span>

    <span class="cp"># If found, add object points, image points (after refining them)</span>
    <span class="k">if</span> <span class="n">ret</span> <span class="o">==</span> <span class="nl">True</span><span class="p">:</span>
        <span class="n">objpoints</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">objp</span><span class="p">)</span>

        <span class="n">corners2</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">cornerSubPix</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span><span class="n">corners</span><span class="p">,</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">criteria</span><span class="p">)</span>
        <span class="n">imgpoints</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">corners</span><span class="p">)</span>

        <span class="cp"># Draw and display the corners</span>
        <span class="n">cv2</span><span class="p">.</span><span class="n">drawChessboardCorners</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">corners2</span><span class="p">,</span> <span class="n">ret</span><span class="p">)</span>
        <span class="n">cv2</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="sc">&#39;img&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
        <span class="n">cv2</span><span class="p">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre>
<p>One image with pattern drawn on it is shown below:</p>
<img alt="image" src="_images/calib_pattern.jpg" />
<p class="rubric">Calibration</p>
<p>So now we have our object points and image points we are ready to go for calibration. For that we use the function, <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1ga3207604e4b1a1758aa66acb6ed5aa65d"><span class="std std-ref">cv2.calibrateCamera()</span></a>. It returns the camera matrix, distortion coefficients, rotation and translation vectors etc.</p>
<pre class="highlight literal-block">
<span></span><span class="n">ret</span><span class="p">,</span> <span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">rvecs</span><span class="p">,</span> <span class="n">tvecs</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">calibrateCamera</span><span class="p">(</span><span class="n">objpoints</span><span class="p">,</span> <span class="n">imgpoints</span><span class="p">,</span> <span class="n">gray</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">::-</span><span class="mi">1</span><span class="p">],</span> <span class="n">None</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span>
</pre>
<p class="rubric">Undistortion</p>
<p>We have got what we were trying. Now we can take an image and undistort it. OpenCV comes with two methods, we will see both. But before that, we can refine the camera matrix based on a free scaling parameter using <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1ga7a6c4e032c97f03ba747966e6ad862b1"><span class="std std-ref">cv2.getOptimalNewCameraMatrix()</span></a>. If the scaling parameter alpha=0, it returns undistorted image with minimum unwanted pixels. So it may even remove some pixels at image corners. If alpha=1, all pixels are retained with some extra black images. It also returns an image ROI which can be used to crop the result.</p>
<p>So we take a new image (left12.jpg in this case. That is the first image in this chapter)</p>
<pre class="highlight literal-block">
<span></span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;left12.jpg&#39;</span><span class="p">)</span>
<span class="n">h</span><span class="p">,</span>  <span class="n">w</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">newcameramtx</span><span class="p">,</span> <span class="n">roi</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">getOptimalNewCameraMatrix</span><span class="p">(</span><span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">h</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">h</span><span class="p">))</span>
</pre>
<p class="rubric">1. Using</p>
<p>This is the shortest path. Just call the function and use ROI obtained above to crop the result.</p>
<pre class="highlight literal-block">
<span></span><span class="cp"># undistort</span>
<span class="n">dst</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">undistort</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">newcameramtx</span><span class="p">)</span>

<span class="cp"># crop the image</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">roi</span>
<span class="n">dst</span> <span class="o">=</span> <span class="n">dst</span><span class="p">[</span><span class="nl">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="nl">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
<span class="n">cv2</span><span class="p">.</span><span class="n">imwrite</span><span class="p">(</span><span class="sc">&#39;calibresult.png&#39;</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</pre>
<p class="rubric">2. Using</p>
<p>This is curved path. First find a mapping function from distorted image to undistorted image. Then use the remap function.</p>
<pre class="highlight literal-block">
<span></span><span class="cp"># undistort</span>
<span class="n">mapx</span><span class="p">,</span> <span class="n">mapy</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">initUndistortRectifyMap</span><span class="p">(</span><span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">newcameramtx</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">h</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">dst</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">remap</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mapx</span><span class="p">,</span> <span class="n">mapy</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">INTER_LINEAR</span><span class="p">)</span>

<span class="cp"># crop the image</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">roi</span>
<span class="n">dst</span> <span class="o">=</span> <span class="n">dst</span><span class="p">[</span><span class="nl">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="nl">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
<span class="n">cv2</span><span class="p">.</span><span class="n">imwrite</span><span class="p">(</span><span class="sc">&#39;calibresult.png&#39;</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span>
</pre>
<p>Both the methods give the same result. See the result below:</p>
<img alt="image" src="_images/calib_result.jpg" />
<p>You can see in the result that all the edges are straight.</p>
<p>Now you can store the camera matrix and distortion coefficients using write functions in Numpy (np.savez, np.savetxt etc) for future uses.</p>
<p class="rubric">Re-projection Error</p>
<p>Re-projection error gives a good estimation of just how exact is the found parameters. This should be as close to zero as possible. Given the intrinsic, distortion, rotation and translation matrices, we first transform the object point to image point using <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1ga1019495a2c8d1743ed5cc23fa0daff8c"><span class="std std-ref">cv2.projectPoints()</span></a>. Then we calculate the absolute norm between what we got with our transformation and the corner finding algorithm. To find the average error we calculate the arithmetical mean of the errors calculate for all the calibration images.</p>
<pre class="highlight literal-block">
<span></span><span class="n">mean_error</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">xrange</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">objpoints</span><span class="p">))</span><span class="o">:</span>
    <span class="n">imgpoints2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">projectPoints</span><span class="p">(</span><span class="n">objpoints</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">rvecs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tvecs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">mtx</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">imgpoints</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">imgpoints2</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">NORM_L2</span><span class="p">)</span><span class="o">/</span><span class="n">len</span><span class="p">(</span><span class="n">imgpoints2</span><span class="p">)</span>
    <span class="n">mean_error</span> <span class="o">+=</span> <span class="n">error</span>

<span class="n">print</span><span class="p">(</span> <span class="s">&quot;total error: {}&quot;</span><span class="p">.</span><a class="reference internal" href="group_core_utils.html#doxid-db-de0-group-core-utils-1ga0cccdb2f73859309b0611cf70b1b9409"><span class="std std-ref">format</span></a><span></span><span class="p">(</span><span class="n">mean_error</span><span class="o">/</span><span class="n">len</span><span class="p">(</span><span class="n">objpoints</span><span class="p">))</span> <span class="p">)</span>
</pre>
<p class="rubric">Additional Resources</p>
<p class="rubric">Exercises</p>
<ol class="arabic simple">
<li>Try camera calibration with circular grid.</li>
</ol>
<p class="rubric">See also:</p>
<p>This function may not be able to find the required pattern in all the images. So one good option is to <a class="reference internal" href="class_cv_FileStorage.html#doxid-d9-df9-classcv-1-1-file-storage-1a26447446dd3fa0644684a045e16399fe"><span class="std std-ref">write</span></a> the code such that, it starts the camera and check each frame for required pattern. Once pattern is obtained, find the corners and store it in a list. Also provides some interval before reading next frame so that we can adjust our chess board in different direction. Continue this process until required number of good patterns are obtained. Even in the example provided here, we are not sure out of 14 images given, how many are good. So we <a class="reference internal" href="class_cv_FileNode.html#doxid-dc-d21-classcv-1-1-file-node-1ab24433dde37f770766481a91983e5f44"><span class="std std-ref">read</span></a> all the images and take the good ones.</p>
<p>Instead of chess board, we can use some circular grid, but then use the function <a class="reference internal" href="group_calib3d.html#doxid-d9-d0c-group-calib3d-1gad1205c4b803a21597c7d6035f5efd775"><span class="std std-ref">cv2.findCirclesGrid()</span></a> to find the pattern. It is said that less number of images are enough when using circular grid.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="page_tutorial_py_depthmap.html" class="btn btn-neutral float-right" title="Depth Map from Stereo Images" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="page_tutorial_py_table_of_contents_calib3d.html" class="btn btn-neutral float-left" title="Camera Calibration and 3D Reconstruction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 1999-2017, OpenCV Maintainers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>