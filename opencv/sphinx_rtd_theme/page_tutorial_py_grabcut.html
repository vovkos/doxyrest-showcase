

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Interactive Foreground Extraction using GrabCut Algorithm &mdash; OpenCV Documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="_static/target-highlight.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-sphinx_rtd_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Morphological Transformations" href="page_tutorial_py_morphological_ops.html" />
    <link rel="prev" title="Fourier Transform" href="page_tutorial_py_fourier_transform.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> OpenCV Documentation
          

          
          </a>

          
            
            
              <div class="version">
                3.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="group_features2d.html">2D Features Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_viz.html">3D Visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_calib3d.html">Camera Calibration and 3D Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_flann.html">Clustering and Search in Multi-Dimensional Spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_photo.html">Computational Photography</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_core.html">Core functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_highgui.html">High-level GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgcodecs.html">Image file reading and writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgproc.html">Image processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_stitching.html">Images stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_objdetect.html">Object Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_shape.html">Shape Distance and Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_superres.html">Super Resolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_video.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videoio.html">Video I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videostab.html">Video Stabilization</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="page_citelist.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_cuda_intro.html">CUDA Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_imgproc_color_conversions.html">Color conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_deprecated.html">Deprecated List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_ml_intro.html">Machine Learning Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_tutorial_root.html">OpenCV Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_index.html">OpenCV modules</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_calib3d.html">Camera Calibration and 3D Reconstruction</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_photo.html">Computational Photography</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_core.html">Core Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_gui.html">Gui Features in OpenCV</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="page_tutorial_py_table_of_contents_imgproc.html">Image Processing in OpenCV</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_canny.html">Canny Edge Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_colorspaces.html">Changing Colorspaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_table_of_contents_contours.html">Contours in OpenCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_geometric_transformations.html">Geometric Transformations of Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_table_of_contents_histograms.html">Histograms in OpenCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_houghcircles.html">Hough Circle Transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_houghlines.html">Hough Line Transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_gradients.html">Image Gradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_pyramids.html">Image Pyramids</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_watershed.html">Image Segmentation with Watershed Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_thresholding.html">Image Thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_table_of_contents_transforms.html">Image Transforms in OpenCV</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Interactive Foreground Extraction using GrabCut Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_morphological_ops.html">Morphological Transformations</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_filtering.html">Smoothing Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_template_matching.html">Template Matching</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_setup.html">Introduction to OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_objdetect.html">Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_bindings.html">OpenCV-Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_video.html">Video Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="page_todo.html">Todo List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_videoio_overview.html">Video I/O with OpenCV Overview</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example_contours2.cpp.html">contours2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_convexhull.cpp.html">convexhull.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_cout_mat.cpp.html">cout_mat.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_demhist.cpp.html">demhist.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_distrans.cpp.html">distrans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_edge.cpp.html">edge.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_ffilldemo.cpp.html">ffilldemo.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_filestorage.cpp.html">filestorage.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_fitellipse.cpp.html">fitellipse.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_grabcut.cpp.html">grabcut.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghcircles.cpp.html">houghcircles.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghlines.cpp.html">houghlines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_kmeans.cpp.html">kmeans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_laplace.cpp.html">laplace.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_lsd_lines.cpp.html">lsd_lines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_minarea.cpp.html">minarea.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_morphology2.cpp.html">morphology2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_pca.cpp.html">pca.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_polar_transforms.cpp.html">polar_transforms.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_segment_objects.cpp.html">segment_objects.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_watershed.cpp.html">watershed.cpp</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="global.html">Global Namespace</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenCV Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_table_of_contents_imgproc.html">Image Processing in OpenCV</a> &raquo;</li>
        
      <li>Interactive Foreground Extraction using GrabCut Algorithm</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="interactive-foreground-extraction-using-grabcut-algorithm">
<span id="doxid-d8-d83-tutorial-py-grabcut"></span><span id="index-0"></span><h1>Interactive Foreground Extraction using GrabCut Algorithm</h1>
<p class="rubric">Goal</p>
<p>In this chapter</p>
<ul class="simple">
<li>We will see GrabCut algorithm to extract foreground in images</li>
<li>We will create an interactive application for this.</li>
</ul>
<p class="rubric">Theory</p>
<p>GrabCut algorithm was designed by Carsten Rother, Vladimir Kolmogorov &amp; Andrew Blake from Microsoft Research Cambridge, UK. in their paper, <a class="reference external" href="http://dl.acm.org/citation.cfm?id=1015720">“GrabCut”: interactive foreground extraction using iterated graph cuts</a>. An algorithm was needed for foreground extraction with minimal user interaction, and the result was GrabCut.</p>
<p>How it works from user point of view ? Initially user draws a rectangle around the foreground region (foreground region should be completely inside the rectangle). Then algorithm segments it iteratively to get the best result. Done. But in some cases, the segmentation won’t be fine, like, it may have marked some foreground region as background and vice versa. In that case, user need to do fine touch-ups. Just give some strokes on the images where some faulty results are there. Strokes basically says *”Hey, this region should be foreground, you marked it background, correct it in next
iteration”* or its opposite for background. Then in the next iteration, you get better results.</p>
<p>See the image below. First player and football is enclosed in a blue rectangle. Then some final touchups with white strokes (denoting foreground) and black strokes (denoting background) is made. And we get a nice result.</p>
<img alt="image" src="_images/grabcut_output1.jpg" />
<p>So what happens in background ?</p>
<ul class="simple">
<li>User inputs the rectangle. Everything outside this rectangle will be taken as sure background (That is the reason it is mentioned before that your rectangle should include all the objects). Everything inside rectangle is unknown. Similarly any user input specifying foreground and background are considered as hard-labelling which means they won’t change in the process.</li>
<li>Computer does an initial labelling depeding on the data we gave. It labels the foreground and background pixels (or it hard-labels)</li>
<li>Now a Gaussian Mixture Model(GMM) is used to model the foreground and background.</li>
<li>Depending on the data we gave, GMM learns and create new pixel distribution. That is, the unknown pixels are labelled either probable foreground or probable background depending on its relation with the other hard-labelled pixels in terms of color statistics (It is just like clustering).</li>
<li>A graph is built from this pixel distribution. Nodes in the graphs are pixels. Additional two nodes are added, <strong>Source node</strong> and <strong>Sink node</strong>. Every foreground pixel is connected to Source node and every background pixel is connected to Sink node.</li>
<li>The weights of edges connecting pixels to source node/end node are defined by the probability of a pixel being foreground/background. The weights between the pixels are defined by the edge information or pixel similarity. If there is a large difference in pixel color, the edge between them will get a low weight.</li>
<li>Then a mincut algorithm is used to segment the graph. It cuts the graph into two separating source node and sink node with minimum cost function. The cost function is the sum of all weights of the edges that are cut. After the cut, all the pixels connected to Source node become foreground and those connected to Sink node become background.</li>
<li>The process is continued until the classification converges.</li>
</ul>
<p>It is illustrated in below image (Image Courtesy: <a class="reference external" href="http://www.cs.ru.ac.za/research/g02m1682/">http://www.cs.ru.ac.za/research/g02m1682/</a>)</p>
<img alt="image" src="_images/grabcut_scheme.jpg" />
<p class="rubric">Demo</p>
<p>Now we go for grabcut algorithm with OpenCV. OpenCV has the function, <a class="reference internal" href="group_imgproc_misc.html#doxid-d7-d1b-group-imgproc-misc-1ga909c1dda50efcbeaa3ce126be862b37f"><span class="std std-ref">cv2.grabCut()</span></a> for this. We will see its arguments first:</p>
<ul class="simple">
<li><em>img</em> - Input image</li>
<li><em>mask</em> - It is a mask image where we specify which areas are background, foreground or probable background/foreground etc. It is done by the following flags, <strong>cv2.GC_BGD, cv2.GC_FGD, cv2.GC_PR_BGD, cv2.GC_PR_FGD</strong>, or simply pass 0,1,2,3 to image.</li>
<li><em>rect</em> - It is the coordinates of a rectangle which includes the foreground object in the format (x,y,w,h)</li>
<li><em>bdgModel</em>, <em>fgdModel</em> - These are arrays used by the algorithm internally. You just create two np.float64 type zero arrays of size (1,65).</li>
<li><em>iterCount</em> - Number of iterations the algorithm should run.</li>
<li><em>mode</em> - It should be <strong>cv2.GC_INIT_WITH_RECT</strong> or <strong>cv2.GC_INIT_WITH_MASK</strong> or combined which decides whether we are drawing rectangle or final touchup strokes.</li>
</ul>
<p>First let’s see with rectangular mode. We load the image, create a similar mask image. We create <em>fgdModel</em> and <em>bgdModel</em>. We give the rectangle parameters. It’s all straight-forward. Let the algorithm run for 5 iterations. Mode should be <em>cv2.GC_INIT_WITH_RECT</em> since we are using rectangle. Then run the grabcut. It modifies the mask image. In the new mask image, pixels will be marked with four flags denoting background/foreground as specified above. So we modify the mask such that all 0-pixels and 2-pixels are put to 0 (ie background) and all 1-pixels and 3-pixels are put to 1(ie foreground pixels). Now our final mask is ready. Just multiply it with input image to get the segmented image.</p>
<pre class="highlight literal-block">
<span></span><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">cv2</span>
<span class="n">from</span> <span class="n">matplotlib</span> <span class="n">import</span> <span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;messi5.jpg&#39;</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">:</span><span class="mi">2</span><span class="p">],</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="n">bgdModel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">65</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">fgdModel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">65</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">rect</span> <span class="o">=</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">450</span><span class="p">,</span><span class="mi">290</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">mask</span><span class="p">,</span><span class="n">rect</span><span class="p">,</span><span class="n">bgdModel</span><span class="p">,</span><span class="n">fgdModel</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">cv2</span><span class="p">.</span><span class="n">GC_INIT_WITH_RECT</span><span class="p">)</span>

<span class="n">mask2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">mask</span><span class="o">==</span><span class="mi">2</span><span class="p">)</span><span class="o">|</span><span class="p">(</span><span class="n">mask</span><span class="o">==</span><span class="mi">0</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="sc">&#39;uint8&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">*</span><span class="n">mask2</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="o">:</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(),</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<p>See the results below:</p>
<img alt="image" src="_images/grabcut_rect.jpg" />
<p>Oops, Messi’s hair is gone. <em>Who likes Messi without his hair?</em> We need to bring it back. So we will give there a fine touchup with 1-pixel (sure foreground). At the same time, Some part of ground has come to picture which we don’t want, and also some logo. We need to remove them. There we give some 0-pixel touchup (sure background). So we modify our resulting mask in previous case as we told now.</p>
<p><em>What I actually did is that, I opened input image in paint application and added another layer to the image. Using brush tool in the paint, I marked missed foreground (hair, shoes, ball etc) with white and unwanted background (like logo, ground etc) with black on this new layer. Then filled remaining background with gray. Then loaded that mask image in OpenCV, edited original mask image we got with corresponding values in newly added mask image. Check the code below:</em></p>
<pre class="highlight literal-block">
<span></span><span class="cp"># newmask is the mask image I manually labelled</span>
<span class="n">newmask</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;newmask.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

<span class="cp"># whereever it is marked white (sure foreground), change mask=1</span>
<span class="cp"># whereever it is marked black (sure background), change mask=0</span>
<span class="n">mask</span><span class="p">[</span><span class="n">newmask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">mask</span><span class="p">[</span><span class="n">newmask</span> <span class="o">==</span> <span class="mi">255</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">mask</span><span class="p">,</span> <span class="n">bgdModel</span><span class="p">,</span> <span class="n">fgdModel</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">grabCut</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">mask</span><span class="p">,</span><span class="n">None</span><span class="p">,</span><span class="n">bgdModel</span><span class="p">,</span><span class="n">fgdModel</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">cv2</span><span class="p">.</span><span class="n">GC_INIT_WITH_MASK</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">((</span><span class="n">mask</span><span class="o">==</span><span class="mi">2</span><span class="p">)</span><span class="o">|</span><span class="p">(</span><span class="n">mask</span><span class="o">==</span><span class="mi">0</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="sc">&#39;uint8&#39;</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">*</span><span class="n">mask</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="o">:</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(),</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<p>See the result below:</p>
<img alt="image" src="_images/grabcut_mask.jpg" />
<p>So that’s it. Here instead of initializing in rect mode, you can directly go into mask mode. Just mark the rectangle area in mask image with 2-pixel or 3-pixel (probable background/foreground). Then mark our sure_foreground with 1-pixel as we did in second example. Then directly apply the grabCut function with mask mode.</p>
<p class="rubric">Additional Resources</p>
<p class="rubric">Exercises</p>
<ol class="arabic simple">
<li>OpenCV samples contain a sample grabcut.py which is an interactive tool using grabcut. Check it. Also watch this <a class="reference external" href="http://www.youtube.com/watch?v=kAwxLTDDAwU">youtube video</a> on how to use it.</li>
<li>Here, you can make this into a interactive sample with drawing rectangle and strokes with mouse, create trackbar to adjust stroke width etc.</li>
</ol>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="page_tutorial_py_morphological_ops.html" class="btn btn-neutral float-right" title="Morphological Transformations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="page_tutorial_py_fourier_transform.html" class="btn btn-neutral float-left" title="Fourier Transform" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 1999-2017, OpenCV Maintainers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>