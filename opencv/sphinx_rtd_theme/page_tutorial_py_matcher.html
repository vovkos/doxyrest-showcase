

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Feature Matching &mdash; OpenCV Documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="_static/target-highlight.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/doxyrest-sphinx_rtd_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Feature Matching + Homography to find Objects" href="page_tutorial_py_feature_homography.html" />
    <link rel="prev" title="FAST Algorithm for Corner Detection" href="page_tutorial_py_fast.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> OpenCV Documentation
          

          
          </a>

          
            
            
              <div class="version">
                3.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="group_features2d.html">2D Features Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_viz.html">3D Visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_calib3d.html">Camera Calibration and 3D Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_flann.html">Clustering and Search in Multi-Dimensional Spaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_photo.html">Computational Photography</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_core.html">Core functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_highgui.html">High-level GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgcodecs.html">Image file reading and writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_imgproc.html">Image processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_stitching.html">Images stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_objdetect.html">Object Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_shape.html">Shape Distance and Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_superres.html">Super Resolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_video.html">Video Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videoio.html">Video I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="group_videostab.html">Video Stabilization</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="page_citelist.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_cuda_intro.html">CUDA Module Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_imgproc_color_conversions.html">Color conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_deprecated.html">Deprecated List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_ml_intro.html">Machine Learning Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_tutorial_root.html">OpenCV Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_index.html">OpenCV modules</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_calib3d.html">Camera Calibration and 3D Reconstruction</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_photo.html">Computational Photography</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_core.html">Core Operations</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="page_tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_brief.html">BRIEF (Binary Robust Independent Elementary Features)</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_fast.html">FAST Algorithm for Corner Detection</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Feature Matching</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_feature_homography.html">Feature Matching + Homography to find Objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_features_harris.html">Harris Corner Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_sift_intro.html">Introduction to SIFT (Scale-Invariant Feature Transform)</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_surf_intro.html">Introduction to SURF (Speeded-Up Robust Features)</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_orb.html">ORB (Oriented FAST and Rotated BRIEF)</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_shi_tomasi.html">Shi-Tomasi Corner Detector &amp; Good Features to Track</a></li>
<li class="toctree-l3"><a class="reference internal" href="page_tutorial_py_features_meaning.html">Understanding Features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_gui.html">Gui Features in OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_imgproc.html">Image Processing in OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_setup.html">Introduction to OpenCV</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_ml.html">Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_objdetect.html">Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_bindings.html">OpenCV-Python Bindings</a></li>
<li class="toctree-l2"><a class="reference internal" href="page_tutorial_py_table_of_contents_video.html">Video Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="page_todo.html">Todo List</a></li>
<li class="toctree-l1"><a class="reference internal" href="page_videoio_overview.html">Video I/O with OpenCV Overview</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example_contours2.cpp.html">contours2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_convexhull.cpp.html">convexhull.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_cout_mat.cpp.html">cout_mat.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_demhist.cpp.html">demhist.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_distrans.cpp.html">distrans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_edge.cpp.html">edge.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_ffilldemo.cpp.html">ffilldemo.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_filestorage.cpp.html">filestorage.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_fitellipse.cpp.html">fitellipse.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_grabcut.cpp.html">grabcut.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghcircles.cpp.html">houghcircles.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_houghlines.cpp.html">houghlines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_kmeans.cpp.html">kmeans.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_laplace.cpp.html">laplace.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_lsd_lines.cpp.html">lsd_lines.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_minarea.cpp.html">minarea.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_morphology2.cpp.html">morphology2.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_pca.cpp.html">pca.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_polar_transforms.cpp.html">polar_transforms.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_segment_objects.cpp.html">segment_objects.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_watershed.cpp.html">watershed.cpp</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="global.html">Global Namespace</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OpenCV Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_root.html">OpenCV-Python Tutorials</a> &raquo;</li>
        
          <li><a href="page_tutorial_py_table_of_contents_feature2d.html">Feature Detection and Description</a> &raquo;</li>
        
      <li>Feature Matching</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="feature-matching">
<span id="doxid-dc-dc3-tutorial-py-matcher"></span><span id="index-0"></span><h1>Feature Matching</h1>
<p class="rubric">Goal</p>
<p>In this chapter</p>
<ul class="simple">
<li>We will see how to match features in one image with others.</li>
<li>We will use the Brute-Force matcher and FLANN Matcher in OpenCV</li>
</ul>
<p class="rubric">Basics of Brute-Force Matcher</p>
<p>Brute-Force matcher is simple. It takes the descriptor of one feature in first set and is matched with all other features in second set using some distance calculation. And the closest one is returned.</p>
<p>For BF matcher, first we have to create the BFMatcher object using <strong>cv2.BFMatcher()</strong>. It takes two optional params. First one is normType. It specifies the distance measurement to be used. By default, it is cv2.NORM_L2. It is good for SIFT, SURF etc (cv2.NORM_L1 is also there). For binary string based descriptors like ORB, BRIEF, BRISK etc, cv2.NORM_HAMMING should be used, which used Hamming distance as measurement. If ORB is using WTA_K == 3 or 4, cv2.NORM_HAMMING2 should be used.</p>
<p>Second param is boolean variable, crossCheck which is false by default. If it is true, Matcher returns only those matches with value (i,j) such that i-th descriptor in set A has j-th descriptor in set B as the best match and vice-versa. That is, the two features in both sets should match each other. It provides consistant result, and is a good alternative to ratio test proposed by D.Lowe in SIFT paper.</p>
<p>Once it is created, two important methods are <em>BFMatcher.match()</em> and <em>BFMatcher.knnMatch()</em>. First one returns the best match. Second method returns k best matches where k is specified by the user. It may be useful when we need to do additional work on that.</p>
<p>Like we used <a class="reference internal" href="group_features2d_draw.html#doxid-d4-d5d-group-features2d-draw-1gab958f8900dd10f14316521c149a60433"><span class="std std-ref">cv2.drawKeypoints()</span></a> to draw keypoints, <a class="reference internal" href="group_features2d_draw.html#doxid-d4-d5d-group-features2d-draw-1ga7421b3941617d7267e3f2311582f49e1"><span class="std std-ref">cv2.drawMatches()</span></a> helps us to draw the matches. It stacks two images horizontally and draw lines from first image to second image showing best matches. There is also <strong>cv2.drawMatchesKnn</strong> which draws all the k best matches. If k=2, it will draw two match-lines for each keypoint. So we have to pass a mask if we want to selectively draw it.</p>
<p>Let’s see one example for each of SURF and ORB (Both use different distance measurements).</p>
<p class="rubric">Brute-Force Matching with ORB Descriptors</p>
<p>Here, we will see a simple example on how to match features between two images. In this case, I have a queryImage and a trainImage. We will try to find the queryImage in trainImage using feature matching. ( The images are /samples/c/box.png and /samples/c/box_in_scene.png)</p>
<p>We are using ORB descriptors to match features. So let’s start with loading images, finding descriptors etc.</p>
<pre class="highlight literal-block">
<span></span><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">cv2</span>
<span class="n">import</span> <span class="n">matplotlib</span><span class="p">.</span><span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>

<span class="n">img1</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>          <span class="err">#</span> <span class="n">queryImage</span>
<span class="n">img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box_in_scene.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="err">#</span> <span class="n">trainImage</span>

<span class="cp"># Initiate ORB detector</span>
<span class="n">orb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">ORB_create</span><span class="p">()</span>

<span class="cp"># find the keypoints and descriptors with ORB</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">orb</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">orb</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>
</pre>
<p>Next we create a BFMatcher object with distance measurement cv2.NORM_HAMMING (since we are using ORB) and crossCheck is switched on for better results. Then we use Matcher.match() method to get the best matches in two images. We sort them in ascending order of their distances so that best matches (with low distance) come to front. Then we draw only first 10 matches (Just for sake of visibility. You can increase it as you like)</p>
<pre class="highlight literal-block">
<span></span><span class="cp"># create BFMatcher object</span>
<span class="n">bf</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">BFMatcher</span><span class="p">(</span><span class="n">cv2</span><span class="p">.</span><span class="n">NORM_HAMMING</span><span class="p">,</span> <span class="n">crossCheck</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

<span class="cp"># Match descriptors.</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">bf</span><span class="p">.</span><span class="n">match</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span><span class="n">des2</span><span class="p">)</span>

<span class="cp"># Sort them in the order of their distance.</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">sorted</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">lambda</span> <span class="nl">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">distance</span><span class="p">)</span>

<span class="cp"># Draw first 10 matches.</span>
<span class="n">img3</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">drawMatches</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">kp1</span><span class="p">,</span><span class="n">img2</span><span class="p">,</span><span class="n">kp2</span><span class="p">,</span><span class="n">matches</span><span class="p">[</span><span class="o">:</span><span class="mi">10</span><span class="p">],</span> <span class="n">flags</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img3</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<p>Below is the result I got:</p>
<img alt="image" src="_images/matcher_result1.jpg" />
<p class="rubric">What is this Matcher Object?</p>
<p>The result of matches = bf.match(des1,des2) line is a list of DMatch objects. This DMatch object has following attributes:</p>
<ul class="simple">
<li>DMatch.distance - Distance between descriptors. The lower, the better it is.</li>
<li>DMatch.trainIdx - Index of the descriptor in train descriptors</li>
<li>DMatch.queryIdx - Index of the descriptor in query descriptors</li>
<li>DMatch.imgIdx - Index of the train image.</li>
</ul>
<p class="rubric">Brute-Force Matching with SIFT Descriptors and Ratio Test</p>
<p>This time, we will use BFMatcher.knnMatch() to get k best matches. In this example, we will take k=2 so that we can apply ratio test explained by D.Lowe in his paper.</p>
<pre class="highlight literal-block">
<span></span><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">cv2</span>
<span class="n">from</span> <span class="n">matplotlib</span> <span class="n">import</span> <span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>

<span class="n">img1</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>          <span class="err">#</span> <span class="n">queryImage</span>
<span class="n">img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box_in_scene.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="err">#</span> <span class="n">trainImage</span>

<span class="cp"># Initiate SIFT detector</span>
<span class="n">sift</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">SIFT</span><span class="p">()</span>

<span class="cp"># find the keypoints and descriptors with SIFT</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">sift</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">sift</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>

<span class="cp"># BFMatcher with default params</span>
<span class="n">bf</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">BFMatcher</span><span class="p">()</span>
<span class="n">matches</span> <span class="o">=</span> <span class="n">bf</span><span class="p">.</span><span class="n">knnMatch</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span><span class="n">des2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="cp"># Apply ratio test</span>
<span class="n">good</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="n">in</span> <span class="nl">matches</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">distance</span> <span class="o">&lt;</span> <span class="mf">0.75</span><span class="o">*</span><span class="n">n</span><span class="p">.</span><span class="nl">distance</span><span class="p">:</span>
        <span class="n">good</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">m</span><span class="p">])</span>

<span class="cp"># cv2.drawMatchesKnn expects list of lists as matches.</span>
<span class="n">img3</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">drawMatchesKnn</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">kp1</span><span class="p">,</span><span class="n">img2</span><span class="p">,</span><span class="n">kp2</span><span class="p">,</span><span class="n">good</span><span class="p">,</span><span class="n">flags</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img3</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<p>See the result below:</p>
<img alt="image" src="_images/matcher_result2.jpg" />
<p class="rubric">FLANN based Matcher</p>
<p>FLANN stands for Fast Library for Approximate Nearest Neighbors. It contains a collection of algorithms optimized for fast nearest neighbor search in large datasets and for high dimensional features. It works more faster than BFMatcher for large datasets. We will see the second example with FLANN based matcher.</p>
<p>For FLANN based matcher, we need to pass two dictionaries which specifies the algorithm to be used, its related parameters etc. First one is IndexParams. For various algorithms, the information to be passed is explained in FLANN docs. As a summary, for algorithms like SIFT, SURF etc. you can pass following:</p>
<pre class="highlight literal-block">
<span></span><span class="n">FLANN_INDEX_KDTREE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">index_params</span> <span class="o">=</span> <span class="n">dict</span><span class="p">(</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">FLANN_INDEX_KDTREE</span><span class="p">,</span> <span class="n">trees</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre>
<p>While using ORB, you can pass the following. The commented values are recommended as per the docs, but it didn’t provide required results in some cases. Other values worked fine.:</p>
<pre class="highlight literal-block">
<span></span><span class="n">FLANN_INDEX_LSH</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">index_params</span><span class="o">=</span> <span class="n">dict</span><span class="p">(</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">FLANN_INDEX_LSH</span><span class="p">,</span>
                   <span class="n">table_number</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="err">#</span> <span class="mi">12</span>
                   <span class="n">key_size</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>     <span class="err">#</span> <span class="mi">20</span>
                   <span class="n">multi_probe_level</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="err">#</span><span class="mi">2</span>
</pre>
<p>Second dictionary is the SearchParams. It specifies the number of times the trees in the index should be recursively traversed. Higher values gives better precision, but also takes more time. If you want to change the value, pass search_params = dict(checks=100).</p>
<p>With these informations, we are good to go.</p>
<pre class="highlight literal-block">
<span></span><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="n">import</span> <span class="n">cv2</span>
<span class="n">from</span> <span class="n">matplotlib</span> <span class="n">import</span> <span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>

<span class="n">img1</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>          <span class="err">#</span> <span class="n">queryImage</span>
<span class="n">img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="sc">&#39;box_in_scene.png&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="err">#</span> <span class="n">trainImage</span>

<span class="cp"># Initiate SIFT detector</span>
<span class="n">sift</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">SIFT</span><span class="p">()</span>

<span class="cp"># find the keypoints and descriptors with SIFT</span>
<span class="n">kp1</span><span class="p">,</span> <span class="n">des1</span> <span class="o">=</span> <span class="n">sift</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>
<span class="n">kp2</span><span class="p">,</span> <span class="n">des2</span> <span class="o">=</span> <span class="n">sift</span><span class="p">.</span><span class="n">detectAndCompute</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span><span class="n">None</span><span class="p">)</span>

<span class="cp"># FLANN parameters</span>
<span class="n">FLANN_INDEX_KDTREE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">index_params</span> <span class="o">=</span> <span class="n">dict</span><span class="p">(</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">FLANN_INDEX_KDTREE</span><span class="p">,</span> <span class="n">trees</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">search_params</span> <span class="o">=</span> <span class="n">dict</span><span class="p">(</span><span class="n">checks</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>   <span class="err">#</span> <span class="n">or</span> <span class="n">pass</span> <span class="n">empty</span> <span class="n">dictionary</span>

<span class="n">flann</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">FlannBasedMatcher</span><span class="p">(</span><span class="n">index_params</span><span class="p">,</span><span class="n">search_params</span><span class="p">)</span>

<span class="n">matches</span> <span class="o">=</span> <span class="n">flann</span><span class="p">.</span><span class="n">knnMatch</span><span class="p">(</span><span class="n">des1</span><span class="p">,</span><span class="n">des2</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="cp"># Need to draw only good matches, so create a mask</span>
<span class="n">matchesMask</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">xrange</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">matches</span><span class="p">))]</span>

<span class="cp"># ratio test as per Lowe&#39;s paper</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">)</span> <span class="n">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span><span class="o">:</span>
    <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">distance</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="o">*</span><span class="n">n</span><span class="p">.</span><span class="nl">distance</span><span class="p">:</span>
        <span class="n">matchesMask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>

<span class="n">draw_params</span> <span class="o">=</span> <span class="n">dict</span><span class="p">(</span><span class="n">matchColor</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span>
                   <span class="n">singlePointColor</span> <span class="o">=</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span>
                   <span class="n">matchesMask</span> <span class="o">=</span> <span class="n">matchesMask</span><span class="p">,</span>
                   <span class="n">flags</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">img3</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">drawMatchesKnn</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">kp1</span><span class="p">,</span><span class="n">img2</span><span class="p">,</span><span class="n">kp2</span><span class="p">,</span><span class="n">matches</span><span class="p">,</span><span class="n">None</span><span class="p">,</span><span class="o">**</span><span class="n">draw_params</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img3</span><span class="p">,),</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<p>See the result below:</p>
<img alt="image" src="_images/matcher_flann.jpg" />
<p class="rubric">Additional Resources</p>
<p class="rubric">Exercises</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="page_tutorial_py_feature_homography.html" class="btn btn-neutral float-right" title="Feature Matching + Homography to find Objects" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="page_tutorial_py_fast.html" class="btn btn-neutral float-left" title="FAST Algorithm for Corner Detection" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 1999-2017, OpenCV Maintainers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>