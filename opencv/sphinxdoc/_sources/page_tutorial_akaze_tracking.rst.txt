.. index:: pair: page; AKAZE and ORB planar tracking
.. _doxid-dc/d16/tutorial_akaze_tracking:

AKAZE and ORB planar tracking
=============================

.. rubric:: Introduction

In this tutorial we will compare *AKAZE* and *ORB* local features using them to find matches between video frames and track object movements.

The algorithm is as follows:

* Detect and describe keypoints on the first frame, manually set object boundaries

* For every next frame:
  
  #. Detect and describe keypoints
  
  #. Match them using bruteforce matcher
  
  #. Estimate homography transformation using RANSAC
  
  #. Filter inliers from all the matches
  
  #. Apply homography transformation to the bounding box to find the object
  
  #. Draw bounding box and inliers, compute inlier ratio as evaluation metric

.. image:: frame.png

.. rubric:: Data

To do the tracking we need a video and object position on the first frame.

You can download our example video and data from `here <https://docs.google.com/file/d/0B72G7D4snftJandBb0taLVJHMFk>`__.

To run the code you have to specify input (camera id or video_file). Then, select a bounding box with the mouse, and press any key to start tracking

.. ref-code-block:: cpp

	./planar_tracking blais.mp4

.. rubric:: Source Code

.. ref-code-block:: cpp

	#include <opencv2/features2d.hpp>
	#include <opencv2/videoio.hpp>
	#include <opencv2/opencv.hpp>
	#include <opencv2/highgui.hpp>      //for imshow
	#include <vector>
	#include <iostream>
	#include <iomanip>
	
	#include "stats.h" // Stats structure definition
	#include "utils.h" // Drawing and printing functions
	
	using namespace :ref:`std <doxid-d8/dcc/namespacestd>`;
	using namespace :ref:`cv <doxid-d2/d75/namespacecv>`;
	
	const double akaze_thresh = 3e-4; // AKAZE detection threshold set to locate about 1000 keypoints
	const double ransac_thresh = 2.5f; // RANSAC inlier threshold
	const double nn_match_ratio = 0.8f; // Nearest-neighbour matching ratio
	const int bb_min_inliers = 100; // Minimal number of inliers to draw bounding box
	const int stats_update_period = 10; // On-screen statistics are updated every 10 frames
	
	namespace example {
	class Tracker
	{
	public:
	    Tracker(:ref:`Ptr\<Feature2D> <doxid-d2/d56/structcv_1_1_ptr>` _detector, :ref:`Ptr\<DescriptorMatcher> <doxid-d2/d56/structcv_1_1_ptr>` _matcher) :
	        detector(_detector),
	        matcher(_matcher)
	    {}
	
	    void setFirstFrame(const :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame, vector<Point2f> bb, string title, Stats& stats);
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` process(const :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame, Stats& stats);
	    :ref:`Ptr\<Feature2D> <doxid-d2/d56/structcv_1_1_ptr>` getDetector() {
	        return detector;
	    }
	protected:
	    :ref:`Ptr\<Feature2D> <doxid-d2/d56/structcv_1_1_ptr>` detector;
	    :ref:`Ptr\<DescriptorMatcher> <doxid-d2/d56/structcv_1_1_ptr>` matcher;
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` first_frame, first_desc;
	    vector<KeyPoint> first_kp;
	    vector<Point2f> object_bb;
	};
	
	void Tracker::setFirstFrame(const :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame, vector<Point2f> bb, string title, Stats& stats)
	{
	    :ref:`cv::Point <doxid-d9/d87/classcv_1_1_point__>` *ptMask = new :ref:`cv::Point <doxid-d9/d87/classcv_1_1_point__>`[bb.size()];
	    const Point* ptContain = { &ptMask[0] };
	    int iSize = static_cast<int>(bb.size());
	    for (size_t i=0; i<bb.size(); i++) {
	        ptMask[i].:ref:`x <doxid-d9/d87/classcv_1_1_point___1a4c96fa7bdbfe390be5ed356edb274ff3>` = static_cast<int>(bb[i].x);
	        ptMask[i].:ref:`y <doxid-d9/d87/classcv_1_1_point___1a157337197338ff199e5df1a393022f15>` = static_cast<int>(bb[i].y);
	    }
	    first_frame = frame.:ref:`clone <doxid-db/de6/classcv_1_1_mat_1ad1c9cc37d66c4e5bd05fae36f62d1cb4>`();
	    :ref:`cv::Mat <doxid-db/de6/classcv_1_1_mat>` matMask = :ref:`cv::Mat::zeros <doxid-db/de6/classcv_1_1_mat_1a0b57b6a326c8876d944d188a46e0f556>`(frame.:ref:`size <doxid-db/de6/classcv_1_1_mat_1a146f8e8dda07d1365a575ab83d9828d1>`(), :ref:`CV_8UC1 <doxid-d1/d1b/group__core__hal__interface_1ga81df635441b21f532fdace401e04f588>`);
	    :ref:`cv::fillPoly <doxid-d6/d6e/group__imgproc__draw_1gaf30888828337aa4c6b56782b5dfbd4b7>`(matMask, &ptContain, &iSize, 1, :ref:`cv::Scalar::all <doxid-d7/d13/classcv_1_1_scalar___1ac1509a4b8454fe7fe29db069e13a2e6f>`(255));
	    detector->:ref:`detectAndCompute <doxid-d9/d9f/classcv_1_1_feature2_d_1a8be0d1c20b08eb867184b8d74c15a677>`(first_frame, matMask, first_kp, first_desc);
	    stats.keypoints = (int)first_kp.size();
	    drawBoundingBox(first_frame, bb);
	    :ref:`putText <doxid-d6/d6e/group__imgproc__draw_1ga5126f47f883d730f633d74f07456c576>`(first_frame, title, :ref:`Point <doxid-dc/d84/group__core__basic_1ga1e83eafb2d26b3c93f09e8338bcab192>`(0, 60), :ref:`FONT_HERSHEY_PLAIN <doxid-d0/de1/group__core_1gga0f9314ea6e35f99bb23f29567fc16e11a08cf3b0a37729fbb62a3007d499cbd8b>`, 5, Scalar::all(0), 4);
	    object_bb = bb;
	    delete[] ptMask;
	}
	
	:ref:`Mat <doxid-db/de6/classcv_1_1_mat>` Tracker::process(const :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame, Stats& stats)
	{
	    vector<KeyPoint> kp;
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` desc;
	    detector->:ref:`detectAndCompute <doxid-d9/d9f/classcv_1_1_feature2_d_1a8be0d1c20b08eb867184b8d74c15a677>`(frame, :ref:`noArray <doxid-dc/d84/group__core__basic_1gad9287b23bba2fed753b36ef561ae7346>`(), kp, desc);
	    stats.keypoints = (int)kp.size();
	
	    vector< vector<DMatch> > matches;
	    vector<KeyPoint> matched1, matched2;
	    matcher->knnMatch(first_desc, desc, matches, 2);
	    for(unsigned i = 0; i < matches.size(); i++) {
	        if(matches[i][0].distance < nn_match_ratio * matches[i][1].distance) {
	            matched1.push_back(first_kp[matches[i][0].queryIdx]);
	            matched2.push_back(      kp[matches[i][0].trainIdx]);
	        }
	    }
	    stats.matches = (int)matched1.size();
	
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` inlier_mask, homography;
	    vector<KeyPoint> inliers1, inliers2;
	    vector<DMatch> inlier_matches;
	    if(matched1.size() >= 4) {
	        homography = :ref:`findHomography <doxid-d9/d0c/group__calib3d_1ga4abc2ece9fab9398f2e560d53c8c9780>`(Points(matched1), Points(matched2),
	                                    :ref:`RANSAC <doxid-d9/d0c/group__calib3d_1gga96ccbb3198badce31862120414bc0d2da724159df258a5d7e29410a6a2f4e6c87>`, ransac_thresh, inlier_mask);
	    }
	
	    if(matched1.size() < 4 || homography.:ref:`empty <doxid-db/de6/classcv_1_1_mat_1abbec3525a852e77998aba034813fded4>`()) {
	        :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` res;
	        :ref:`hconcat <doxid-d2/de8/group__core__array_1gaf9771c991763233866bf76b5b5d1776f>`(first_frame, frame, res);
	        stats.inliers = 0;
	        stats.ratio = 0;
	        return res;
	    }
	    for(unsigned i = 0; i < matched1.size(); i++) {
	        if(inlier_mask.:ref:`at <doxid-db/de6/classcv_1_1_mat_1aa5d20fc86d41d59e4d71ae93daee9726>`<:ref:`uchar <doxid-d1/d1b/group__core__hal__interface_1ga65f85814a8290f9797005d3b28e7e5fc>`>(i)) {
	            int new_i = static_cast<int>(inliers1.size());
	            inliers1.push_back(matched1[i]);
	            inliers2.push_back(matched2[i]);
	            inlier_matches.push_back(:ref:`DMatch <doxid-d9/db0/classcv_1_1_d_match>`(new_i, new_i, 0));
	        }
	    }
	    stats.inliers = (int)inliers1.size();
	    stats.ratio = stats.inliers * 1.0 / stats.matches;
	
	    vector<Point2f> new_bb;
	    :ref:`perspectiveTransform <doxid-d2/de8/group__core__array_1gad327659ac03e5fd6894b90025e6900a7>`(object_bb, new_bb, homography);
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame_with_bb = frame.:ref:`clone <doxid-db/de6/classcv_1_1_mat_1ad1c9cc37d66c4e5bd05fae36f62d1cb4>`();
	    if(stats.inliers >= bb_min_inliers) {
	        drawBoundingBox(frame_with_bb, new_bb);
	    }
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` res;
	    :ref:`drawMatches <doxid-d4/d5d/group__features2d__draw_1ga7421b3941617d7267e3f2311582f49e1>`(first_frame, inliers1, frame_with_bb, inliers2,
	                inlier_matches, res,
	                :ref:`Scalar <doxid-dc/d84/group__core__basic_1ga599fe92e910c027be274233eccad7beb>`(255, 0, 0), :ref:`Scalar <doxid-dc/d84/group__core__basic_1ga599fe92e910c027be274233eccad7beb>`(255, 0, 0));
	    return res;
	}
	}
	
	int main(int argc, char **argv)
	{
	    if(argc < 2) {
	        cerr << "Usage: " << endl
	             << "akaze_track input_path" << endl
	             << "  (input_path can be a camera id, like 0,1,2 or a video filename)" << endl;
	        return 1;
	    }
	
	    std::string video_name = argv[1];
	    std::stringstream ssFormat;
	    ssFormat << atoi(argv[1]);
	
	    :ref:`VideoCapture <doxid-df/dcb/classcv_1_1_video_capture>` video_in;
	    if (video_name.compare(ssFormat.str())==0) {    //test str==str(num)
	        video_in.:ref:`open <doxid-df/dcb/classcv_1_1_video_capture_1ab5b7391cd5ec50e7237e575a758f6f05>`(atoi(argv[1]));
	    }
	    else {
	        video_in.:ref:`open <doxid-df/dcb/classcv_1_1_video_capture_1ab5b7391cd5ec50e7237e575a758f6f05>`(video_name);
	    }
	
	    if(!video_in.:ref:`isOpened <doxid-df/dcb/classcv_1_1_video_capture_1a9d2ca36789e7fcfe7a7be3b328038585>`()) {
	        cerr << "Couldn't open " << argv[1] << endl;
	        return 1;
	    }
	
	    Stats stats, akaze_stats, orb_stats;
	    :ref:`Ptr\<AKAZE> <doxid-d2/d56/structcv_1_1_ptr>` akaze = AKAZE::create();
	    akaze->:ref:`setThreshold <doxid-d4/df2/classcv_1_1_a_k_a_z_e_1aaeec869ae038190ffac3f38174058b25>`(akaze_thresh);
	    :ref:`Ptr\<ORB> <doxid-d2/d56/structcv_1_1_ptr>` orb = ORB::create();
	    :ref:`Ptr\<DescriptorMatcher> <doxid-d2/d56/structcv_1_1_ptr>` matcher = DescriptorMatcher::create("BruteForce-Hamming");
	    example::Tracker akaze_tracker(akaze, matcher);
	    example::Tracker orb_tracker(orb, matcher);
	
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` frame;
	    video_in >> frame;
	    :ref:`namedWindow <doxid-d7/dfc/group__highgui_1ga5afdf8410934fd099df85c75b2e0888b>`(video_name, :ref:`WINDOW_NORMAL <doxid-d7/dfc/group__highgui_1ggabf7d2c5625bc59ac130287f925557ac3a29e45c5af696f73ce5e153601e5ca0f1>`);
	    :ref:`cv::resizeWindow <doxid-d7/dfc/group__highgui_1ga9e80e080f7ef33f897e415358aee7f7e>`(video_name, frame.cols, frame.rows);
	
	    cout << "Please select a bounding box, and press any key to continue." << endl;
	    vector<Point2f> bb;
	    :ref:`cv::Rect <doxid-d6/db0/classcv_1_1_rect__>` uBox = :ref:`cv::selectROI <doxid-d7/dfc/group__highgui_1ga8daf4730d3adf7035b6de9be4c469af5>`(video_name, frame);
	    bb.push_back(:ref:`cv::Point2f <doxid-d9/d87/classcv_1_1_point__>`(static_cast<float>(uBox.:ref:`x <doxid-d6/db0/classcv_1_1_rect___1a2cadfdc3b4b7dbf8085622b27e044572>`), static_cast<float>(uBox.:ref:`y <doxid-d6/db0/classcv_1_1_rect___1a6a4860e984df1752623b6ce2a8bde73a>`)));
	    bb.push_back(:ref:`cv::Point2f <doxid-d9/d87/classcv_1_1_point__>`(static_cast<float>(uBox.:ref:`x <doxid-d6/db0/classcv_1_1_rect___1a2cadfdc3b4b7dbf8085622b27e044572>`+uBox.:ref:`width <doxid-d6/db0/classcv_1_1_rect___1a6c16a3bce912faa4fe5be42d7f1b53fe>`), static_cast<float>(uBox.:ref:`y <doxid-d6/db0/classcv_1_1_rect___1a6a4860e984df1752623b6ce2a8bde73a>`)));
	    bb.push_back(:ref:`cv::Point2f <doxid-d9/d87/classcv_1_1_point__>`(static_cast<float>(uBox.:ref:`x <doxid-d6/db0/classcv_1_1_rect___1a2cadfdc3b4b7dbf8085622b27e044572>`+uBox.:ref:`width <doxid-d6/db0/classcv_1_1_rect___1a6c16a3bce912faa4fe5be42d7f1b53fe>`), static_cast<float>(uBox.:ref:`y <doxid-d6/db0/classcv_1_1_rect___1a6a4860e984df1752623b6ce2a8bde73a>`+uBox.:ref:`height <doxid-d6/db0/classcv_1_1_rect___1a6fed06513cedd76652389e38c7b1222e>`)));
	    bb.push_back(:ref:`cv::Point2f <doxid-d9/d87/classcv_1_1_point__>`(static_cast<float>(uBox.:ref:`x <doxid-d6/db0/classcv_1_1_rect___1a2cadfdc3b4b7dbf8085622b27e044572>`), static_cast<float>(uBox.:ref:`y <doxid-d6/db0/classcv_1_1_rect___1a6a4860e984df1752623b6ce2a8bde73a>`+uBox.:ref:`height <doxid-d6/db0/classcv_1_1_rect___1a6fed06513cedd76652389e38c7b1222e>`)));
	
	    akaze_tracker.setFirstFrame(frame, bb, "AKAZE", stats);
	    orb_tracker.setFirstFrame(frame, bb, "ORB", stats);
	
	    Stats akaze_draw_stats, orb_draw_stats;
	    :ref:`Mat <doxid-db/de6/classcv_1_1_mat>` akaze_res, orb_res, res_frame;
	    int i = 0;
	    for(;;) {
	        i++;
	        bool update_stats = (i % stats_update_period == 0);
	        video_in >> frame;
	        // stop the program if no more images
	        if(frame.empty()) break;
	
	        akaze_res = akaze_tracker.process(frame, stats);
	        akaze_stats += stats;
	        if(update_stats) {
	            akaze_draw_stats = stats;
	        }
	
	        orb->:ref:`setMaxFeatures <doxid-dc/dca/classcv_1_1_o_r_b_1aca471cb82c03b14d3e824e4dcccf90b7>`(stats.keypoints);
	        orb_res = orb_tracker.process(frame, stats);
	        orb_stats += stats;
	        if(update_stats) {
	            orb_draw_stats = stats;
	        }
	
	        drawStatistics(akaze_res, akaze_draw_stats);
	        drawStatistics(orb_res, orb_draw_stats);
	        :ref:`vconcat <doxid-d2/de8/group__core__array_1ga744f53b69f6e4f12156cdde4e76aed27>`(akaze_res, orb_res, res_frame);
	        :ref:`cv::imshow <doxid-d7/dfc/group__highgui_1ga453d42fe4cb60e5723281a89973ee563>`(video_name, res_frame);
	        if(:ref:`waitKey <doxid-d7/dfc/group__highgui_1ga5628525ad33f52eab17feebcfba38bd7>`(1)==27) break; //quit on ESC button
	    }
	    akaze_stats /= i - 1;
	    orb_stats /= i - 1;
	    printStatistics("AKAZE", akaze_stats);
	    printStatistics("ORB", orb_stats);
	    return 0;
	}

.. rubric:: Explanation

.. rubric:: Tracker class

This class implements algorithm described abobve using given feature detector and descriptor matcher.

* **Setting up the first frame**
  
  .. ref-code-block:: cpp
  
  	void Tracker::setFirstFrame(const Mat frame, vector<Point2f> bb, string title, Stats& stats)
  	{
  	    first_frame = frame.clone();
  	    (*detector)(first_frame, :ref:`noArray <doxid-dc/d84/group__core__basic_1gad9287b23bba2fed753b36ef561ae7346>`(), first_kp, first_desc);
  	    stats.keypoints = (int)first_kp.size();
  	    drawBoundingBox(first_frame, bb);
  	    :ref:`putText <doxid-d6/d6e/group__imgproc__draw_1ga5126f47f883d730f633d74f07456c576>`(first_frame, title, :ref:`Point <doxid-dc/d84/group__core__basic_1ga1e83eafb2d26b3c93f09e8338bcab192>`(0, 60), :ref:`FONT_HERSHEY_PLAIN <doxid-d0/de1/group__core_1gga0f9314ea6e35f99bb23f29567fc16e11a08cf3b0a37729fbb62a3007d499cbd8b>`, 5, Scalar::all(0), 4);
  	    object_bb = bb;
  	}
  
  We compute and store keypoints and descriptors from the first frame and prepare it for the output.
  
  We need to save number of detected keypoints to make sure both detectors locate roughly the same number of those.

* **Processing frames**
  
  #. Locate keypoints and compute descriptors
     
     .. ref-code-block:: cpp
     
     	(*detector)(frame, :ref:`noArray <doxid-dc/d84/group__core__basic_1gad9287b23bba2fed753b36ef561ae7346>`(), kp, desc);
     
     To find matches between frames we have to locate the keypoints first.
     
     In this tutorial detectors are set up to find about 1000 keypoints on each frame.
  
  #. Use 2-nn matcher to find correspondences
     
     .. ref-code-block:: cpp
     
     	matcher->knnMatch(first_desc, desc, matches, 2);
     	for(unsigned i = 0; i < matches.size(); i++) {
     	    if(matches[i][0].distance < nn_match_ratio * matches[i][1].distance) {
     	        matched1.push_back(first_kp[matches[i][0].queryIdx]);
     	        matched2.push_back(      kp[matches[i][0].trainIdx]);
     	    }
     	}
     
     If the closest match is *nn_match_ratio* closer than the second closest one, then it's a match.
  
  #. Use *RANSAC* to estimate homography transformation
     
     .. ref-code-block:: cpp
     
     	homography = :ref:`findHomography <doxid-d9/d0c/group__calib3d_1ga4abc2ece9fab9398f2e560d53c8c9780>`(Points(matched1), Points(matched2),
     	                            :ref:`RANSAC <doxid-d9/d0c/group__calib3d_1gga96ccbb3198badce31862120414bc0d2da724159df258a5d7e29410a6a2f4e6c87>`, ransac_thresh, inlier_mask);
     
     If there are at least 4 matches we can use random sample consensus to estimate image transformation.
  
  #. Save the inliers
     
     .. ref-code-block:: cpp
     
     	for(unsigned i = 0; i < matched1.size(); i++) {
     	    if(inlier_mask.:ref:`at <doxid-db/de6/classcv_1_1_mat_1aa5d20fc86d41d59e4d71ae93daee9726>`<:ref:`uchar <doxid-d1/d1b/group__core__hal__interface_1ga65f85814a8290f9797005d3b28e7e5fc>`>(i)) {
     	        int new_i = static_cast<int>(inliers1.size());
     	        inliers1.push_back(matched1[i]);
     	        inliers2.push_back(matched2[i]);
     	        inlier_matches.push_back(DMatch(new_i, new_i, 0));
     	    }
     	}
     
     Since *findHomography* computes the inliers we only have to save the chosen points and matches.
  
  #. Project object bounding box
     
     .. ref-code-block:: cpp
     
     	:ref:`perspectiveTransform <doxid-d2/de8/group__core__array_1gad327659ac03e5fd6894b90025e6900a7>`(object_bb, new_bb, homography);
     
     If there is a reasonable number of inliers we can use estimated transformation to locate the object.

.. rubric:: Results

You can watch the resulting `video on youtube <http://www.youtube.com/watch?v=LWY-w8AGGhE>`__.

*AKAZE* statistics:

.. ref-code-block:: cpp

	Matches      626
	Inliers      410
	Inlier ratio 0.58
	Keypoints    1117

*ORB* statistics:

.. ref-code-block:: cpp

	Matches      504
	Inliers      319
	Inlier ratio 0.56
	Keypoints    1112

