
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Understanding K-Means Clustering &#8212; OpenCV Documentation</title>
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-sphinxdoc.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script type="text/javascript" src="_static/target-highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="K-Nearest Neighbour" href="page_tutorial_py_knn_index.html" />
    <link rel="prev" title="K-Means Clustering in OpenCV" href="page_tutorial_py_kmeans_opencv.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="page_tutorial_py_knn_index.html" title="K-Nearest Neighbour"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="page_tutorial_py_kmeans_opencv.html" title="K-Means Clustering in OpenCV"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">OpenCV Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="page_tutorial_py_root.html" >OpenCV-Python Tutorials</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="page_tutorial_py_table_of_contents_ml.html" >Machine Learning</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="page_tutorial_py_kmeans_index.html" accesskey="U">K-Means Clustering</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="page_tutorial_py_kmeans_opencv.html"
                        title="previous chapter">K-Means Clustering in OpenCV</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="page_tutorial_py_knn_index.html"
                        title="next chapter">K-Nearest Neighbour</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="understanding-k-means-clustering">
<span id="doxid-de-d4d-tutorial-py-kmeans-understanding"></span><span id="index-0"></span><h1>Understanding K-Means Clustering</h1>
<p class="rubric">Goal</p>
<p>In this chapter, we will understand the concepts of K-Means Clustering, how it works etc.</p>
<p class="rubric">Theory</p>
<p>We will deal this with an example which is commonly used.</p>
<p class="rubric">T-shirt size problem</p>
<p>Consider a company, which is going to release a new model of T-shirt to market. Obviously they will have to manufacture models in different sizes to satisfy people of all sizes. So the company make a data of people’s height and weight, and plot them on to a graph, as below:</p>
<img alt="image" src="_images/tshirt.jpg" />
<p>Company can’t create t-shirts with all the sizes. Instead, they divide people to Small, Medium and Large, and manufacture only these 3 models which will fit into all the people. This grouping of people into three groups can be done by k-means clustering, and algorithm provides us best 3 sizes, which will satisfy all the people. And if it doesn’t, company can divide people to more groups, may be five, and so on. Check image below :</p>
<img alt="image" src="_images/tshirt_grouped.jpg" />
<p class="rubric">How does it work ?</p>
<p>This algorithm is an iterative process. We will explain it step-by-step with the help of images.</p>
<p>Consider a set of data as below ( You can consider it as t-shirt problem). We need to cluster this data into two groups.</p>
<img alt="image" src="_images/testdata.jpg" />
<p><strong>Step : 1</strong> - Algorithm randomly chooses two centroids, <span class="math notranslate nohighlight">\(C1\)</span> and <span class="math notranslate nohighlight">\(C2\)</span> (sometimes, any two data are taken as the centroids).</p>
<p><strong>Step : 2</strong> - It calculates the distance from each point to both centroids. If a test data is more closer to <span class="math notranslate nohighlight">\(C1\)</span>, then that data is labelled with ‘0’. If it is closer to <span class="math notranslate nohighlight">\(C2\)</span>, then labelled as ‘1’ (If more centroids are there, labelled as ‘2’,‘3’ etc).</p>
<p>In our case, we will color all ‘0’ labelled with red, and ‘1’ labelled with blue. So we get following image after above operations.</p>
<img alt="image" src="_images/initial_labelling.jpg" />
<p><strong>Step : 3</strong> - Next we calculate the average of all blue points and red points separately and that will be our new centroids. That is <span class="math notranslate nohighlight">\(C1\)</span> and <span class="math notranslate nohighlight">\(C2\)</span> shift to newly calculated centroids. (Remember, the images shown are not true values and not to true scale, it is just for demonstration only).</p>
<p>And again, perform step 2 with new centroids and label data to ‘0’ and ‘1’.</p>
<p>So we get result as below :</p>
<img alt="image" src="_images/update_centroid.jpg" />
<p>Now <strong>Step - 2</strong> and <strong>Step - 3</strong> are iterated until both centroids are converged to fixed points. *(Or it may be stopped depending on the criteria we provide, like maximum number of iterations, or a specific accuracy is reached etc.)* <strong>These points are such that sum of distances between test data and their corresponding centroids are minimum</strong>. Or simply, sum of distances between <span class="math notranslate nohighlight">\(C1 \leftrightarrow Red\_Points\)</span> and <span class="math notranslate nohighlight">\(C2 \leftrightarrow Blue\_Points\)</span> is minimum.</p>
<div class="math notranslate nohighlight">
\[minimize \;\bigg[J = \sum_{All\: Red\_Points}distance(C1,Red\_Point) + \sum_{All\: Blue\_Points}distance(C2,Blue\_Point)\bigg]\]</div>
<p>Final result almost looks like below :</p>
<img alt="image" src="_images/final_clusters.jpg" />
<p>So this is just an intuitive understanding of K-Means Clustering. For more details and mathematical explanation, please read any standard machine learning textbooks or check links in additional resources. It is just a top layer of K-Means clustering. There are a lot of modifications to this algorithm like, how to choose the initial centroids, how to speed up the iteration process etc.</p>
<p class="rubric">Additional Resources</p>
<ol class="arabic simple">
<li><a class="reference external" href="https://www.coursera.org/course/ml">Machine Learning Course</a>, Video lectures by Prof. Andrew Ng (Some of the images are taken from this)</li>
</ol>
<p class="rubric">Exercises</p>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="page_tutorial_py_knn_index.html" title="K-Nearest Neighbour"
             >next</a> |</li>
        <li class="right" >
          <a href="page_tutorial_py_kmeans_opencv.html" title="K-Means Clustering in OpenCV"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">OpenCV Documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="page_tutorial_py_root.html" >OpenCV-Python Tutorials</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="page_tutorial_py_table_of_contents_ml.html" >Machine Learning</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="page_tutorial_py_kmeans_index.html" >K-Means Clustering</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 1999-2017, OpenCV Maintainers.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.5.
    </div>
  </body>
</html>